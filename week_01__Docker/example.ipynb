{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fd2eacd-c3ee-429f-9e53-03fdf253b9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "                    .appName('helloSpark')\n",
    "                    .getOrCreate()\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3ec7cc-5d7b-4319-b704-f2fc139af563",
   "metadata": {},
   "source": [
    "Further info on Spark sessions:  \n",
    "https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/spark_session.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01f63dc4-1b2f-4959-9437-24fa9f592b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://82c14b214d5e:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>helloSpark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0xffff7e390590>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ce07dab-127a-47b9-8b41-fe5ff62fb668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's generate some data for analysis\n",
    "\n",
    "import random\n",
    "\n",
    "names = [\"Alice\", \"Ben\", \"Charles\", \"Daisy\"]\n",
    "start_range = 900\n",
    "end_range = 5000\n",
    "python_data = [[random.choice(names),random.randint(start_range,end_range)] for i in range(500000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a7fb01b-149a-416e-a09a-6ef50af25e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To read in a Python object (list, dict), we can use spark.createDataFrame\n",
    "# We define a schema to have nicer column names and avoid Spark having to infer the schema\n",
    "schema = \"name STRING, salary INT\"\n",
    "\n",
    "df = spark.createDataFrame(python_data,schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44bc08ce-a374-499c-b98c-2e957dbebd0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|   name|salary|\n",
      "+-------+------+\n",
      "|  Alice|  1525|\n",
      "|Charles|  2539|\n",
      "|Charles|  1567|\n",
      "|    Ben|  4256|\n",
      "|  Alice|  1578|\n",
      "|Charles|  1958|\n",
      "|  Daisy|  1523|\n",
      "|Charles|   910|\n",
      "|  Daisy|  1232|\n",
      "|    Ben|  2907|\n",
      "|Charles|  2945|\n",
      "|Charles|  3837|\n",
      "|Charles|  1644|\n",
      "|Charles|  1381|\n",
      "|Charles|  2296|\n",
      "|  Daisy|  2964|\n",
      "|  Daisy|  3046|\n",
      "|  Alice|  4287|\n",
      "|  Alice|  2111|\n",
      "|  Alice|  4366|\n",
      "+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# to display some rows, you can use .show() \n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d767b21f-c3fe-4516-9360-8dfb091bcd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = (df.groupBy(\"name\")\n",
    "          .avg(\"salary\")\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c569ead7-8bb5-4a5e-8085-f7e6f690b3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|   name|       avg(salary)|\n",
      "+-------+------------------+\n",
      "|Charles| 2955.559039107582|\n",
      "|    Ben| 2953.736564242023|\n",
      "|  Alice|2948.4433056398784|\n",
      "|  Daisy| 2945.029207766338|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_new.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc6c62f-d547-4f83-8fa6-5784aa35138b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Many of the functions hide behind spark.sql.functions\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "(df_new.select(\n",
    "    \"name\"\n",
    "    ,\"avg(salary)\"\n",
    "    ,F.round(\"avg(salary)\").alias(\"average\")\n",
    "    ).show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3474a14-484b-433e-a794-c5533d4b5087",
   "metadata": {},
   "source": [
    "The following is for a comparison with the popular Python package `pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ce745d0-a5d7-435a-9e40-1a3d01b8e59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "pd_df = pd.DataFrame(python_data,columns=[\"name\",\"salary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7590a6d-41c5-453d-8cdc-74e38f313634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>1525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Charles</td>\n",
       "      <td>2539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charles</td>\n",
       "      <td>1567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ben</td>\n",
       "      <td>4256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alice</td>\n",
       "      <td>1578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>Daisy</td>\n",
       "      <td>4527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>Alice</td>\n",
       "      <td>2042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>Daisy</td>\n",
       "      <td>4492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>Alice</td>\n",
       "      <td>3929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>Alice</td>\n",
       "      <td>1875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           name  salary\n",
       "0         Alice    1525\n",
       "1       Charles    2539\n",
       "2       Charles    1567\n",
       "3           Ben    4256\n",
       "4         Alice    1578\n",
       "...         ...     ...\n",
       "499995    Daisy    4527\n",
       "499996    Alice    2042\n",
       "499997    Daisy    4492\n",
       "499998    Alice    3929\n",
       "499999    Alice    1875\n",
       "\n",
       "[500000 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19bde6d2-ebf6-4e88-ae66-7f8bf6e23883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alice</th>\n",
       "      <td>2948.443306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ben</th>\n",
       "      <td>2953.736564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Charles</th>\n",
       "      <td>2955.559039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daisy</th>\n",
       "      <td>2945.029208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              salary\n",
       "name                \n",
       "Alice    2948.443306\n",
       "Ben      2953.736564\n",
       "Charles  2955.559039\n",
       "Daisy    2945.029208"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_df.groupby(\"name\").mean(\"salary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0463103-efad-4c27-8698-bea7c575e7e9",
   "metadata": {},
   "source": [
    "Which of these seemed to be faster?  \n",
    "Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a323d65",
   "metadata": {},
   "source": [
    "Let's have a quick walkthrough of a few more PySpark methods.  \n",
    "For a longer (full) list of methods, see:  \n",
    "https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/dataframe.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "048b9e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+----------+------+\n",
      "|emp_id| name|department|salary|\n",
      "+------+-----+----------+------+\n",
      "|     1| John|        HR| 50000|\n",
      "|     2|Alice|        IT| 60000|\n",
      "|     3|  Bob|   Finance| 55000|\n",
      "+------+-----+----------+------+\n",
      "\n",
      "+----------+-------+\n",
      "|department|manager|\n",
      "+----------+-------+\n",
      "|        HR|   Anna|\n",
      "|        IT|  David|\n",
      "|   Finance|  Sarah|\n",
      "+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load CSV files into DataFrames\n",
    "employees_df = spark.read.option(\"header\", \"true\").csv(\"input/employees.csv\")\n",
    "departments_df = spark.read.option(\"header\", \"true\").csv(\"input/departments.csv\")\n",
    "\n",
    "employees_df.show()\n",
    "departments_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5cffedd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+----------+------+\n",
      "|emp_id| name|department|salary|\n",
      "+------+-----+----------+------+\n",
      "|     1| John|        HR| 50000|\n",
      "|     2|Alice|        IT| 60000|\n",
      "|     3|  Bob|   Finance| 55000|\n",
      "+------+-----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#convert salary from string to integer for proper filtering\n",
    "employees_df = employees_df.withColumn(\"salary\", F.col(\"salary\").cast(\"integer\"))\n",
    "\n",
    "employees_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "42ed39aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# use .filter() for ... filtering.\n",
    "filtered_df = employees_df.filter(F.col(\"salary\") > 55000)\n",
    "\n",
    "# use .select() for ... selecting (columns).\n",
    "selected_df = filtered_df.select(\"emp_id\", \"name\", \"department\", \"salary\")\n",
    "\n",
    "# use withColumnRenamed for renaming columns\n",
    "renamed_df = selected_df.withColumnRenamed(\"emp_id\", \"employee_id\")\n",
    "\n",
    "# use selectExpr() for projecting SQL expressions\n",
    "expr_df = renamed_df.selectExpr(\"employee_id\", \"name\", \"department\", \"salary\", \"salary / 12 as monthly_salary\")\n",
    "\n",
    "# use .join() for ... joining. Let's join with departments DataFrame on the 'department' column\n",
    "joined_df = expr_df.join(departments_df, on=\"department\", how=\"inner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a36336f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# .write for writing. There are multiple more options you can see in the next classes.\n",
    "joined_df.write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"output/joined_employees\")\n",
    "\n",
    "# NB - Spark has lazy evaluation. It will only execute the code when it needs to.\n",
    "# This means that you can chain multiple transformations and actions together without any performance hit.\n",
    "# The code will only be executed when you call an action like .show() or .write()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1ffdbe44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: timestamp_ntz (nullable = true)\n",
      " |-- province_thai: string (nullable = true)\n",
      " |-- province_eng: string (nullable = true)\n",
      " |-- region_thai: string (nullable = true)\n",
      " |-- region_eng: string (nullable = true)\n",
      " |-- variable: string (nullable = true)\n",
      " |-- value: double (nullable = true)\n",
      "\n",
      "+-------------------+---------------+--------------------+-----------+----------+------------------+-----+\n",
      "|               date|  province_thai|        province_eng|region_thai|region_eng|          variable|value|\n",
      "+-------------------+---------------+--------------------+-----------+----------+------------------+-----+\n",
      "|2019-01-01 00:00:00|  กรุงเทพมหานคร|             Bangkok|    ภาคกลาง|   central|ratio_tourist_stay|93.37|\n",
      "|2019-01-01 00:00:00|         ลพบุรี|            Lopburi |    ภาคกลาง|   central|ratio_tourist_stay|61.32|\n",
      "|2019-01-01 00:00:00|พระนครศรีอยุธยา|Phra Nakhon Si Ay...|    ภาคกลาง|   central|ratio_tourist_stay|73.37|\n",
      "|2019-01-01 00:00:00|        สระบุรี|           Saraburi |    ภาคกลาง|   central|ratio_tourist_stay|67.33|\n",
      "|2019-01-01 00:00:00|         ชัยนาท|            Chainat |    ภาคกลาง|   central|ratio_tourist_stay|79.31|\n",
      "+-------------------+---------------+--------------------+-----------+----------+------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "Total records: 30800\n",
      "+-------+-------------+--------------+-----------+----------+--------------+-------------------+\n",
      "|summary|province_thai|  province_eng|region_thai|region_eng|      variable|              value|\n",
      "+-------+-------------+--------------+-----------+----------+--------------+-------------------+\n",
      "|  count|        30800|         30800|      30800|     30800|         30800|              30800|\n",
      "|   mean|         NULL|           NaN|       NULL|      NULL|          NULL|3.360336825309471E8|\n",
      "| stddev|         NULL|           NaN|       NULL|      NULL|          NULL|2.994696582046674E9|\n",
      "|    min|       กระบี่|Amnat Charoen |    ภาคกลาง|   central|no_tourist_all|            -4250.0|\n",
      "|    max|   แม่ฮ่องสอน|     Yasothon |     ภาคใต้|     south|  revenue_thai|       1.1028728E11|\n",
      "+-------+-------------+--------------+-----------+----------+--------------+-------------------+\n",
      "\n",
      "+-------------------+-----------------+---------------------------------+--------------------------------------+\n",
      "|               date|     province_eng|no_percentage_of_foreign_tourists|revenue_percentage_of_foreign_tourists|\n",
      "+-------------------+-----------------+---------------------------------+--------------------------------------+\n",
      "|2019-05-01 00:00:00|Ubon Ratchathani |                           0.0459|                                0.0796|\n",
      "|2022-09-01 00:00:00|        Saraburi |                           0.0039|                                0.0037|\n",
      "|2020-05-01 00:00:00|             Nan |                              0.0|                                   0.0|\n",
      "|2020-08-01 00:00:00|         Sisaket |                              0.0|                                   0.0|\n",
      "|2019-08-01 00:00:00|           Surin |                            0.017|                                0.0249|\n",
      "+-------------------+-----------------+---------------------------------+--------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, round\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"ThailandTourismAnalysis\").getOrCreate()\n",
    "\n",
    "# Read Parquet File\n",
    "df = spark.read.parquet(\"thailand_domestic_tourism_2019_2023_ver2.parquet\")\n",
    "\n",
    "# Display Schema\n",
    "df.printSchema()\n",
    "\n",
    "# Show Sample Data\n",
    "df.show(5)\n",
    "\n",
    "# Exploratory Data Analysis\n",
    "print(f\"Total records: {df.count()}\")\n",
    "df.describe().show()\n",
    "\n",
    "# Assuming the correct columns are 'variable' and 'value'\n",
    "# Pivot the DataFrame to get the required columns\n",
    "pivot_df = df.groupBy(\"date\", \"province_eng\").pivot(\"variable\").sum(\"value\")\n",
    "\n",
    "# Calculate Required Aggregations\n",
    "aggregated_df = pivot_df.withColumn(\n",
    "    \"no_percentage_of_foreign_tourists\",\n",
    "    round(col(\"no_tourist_foreign\") / col(\"no_tourist_all\"), 4)\n",
    ").withColumn(\n",
    "    \"revenue_percentage_of_foreign_tourists\",\n",
    "    round(col(\"revenue_foreign\") / col(\"revenue_all\"), 4)\n",
    ").select(\n",
    "    \"date\", \"province_eng\", \"no_percentage_of_foreign_tourists\", \"revenue_percentage_of_foreign_tourists\"\n",
    ")\n",
    "\n",
    "# Show Aggregated Data\n",
    "aggregated_df.show(5)\n",
    "\n",
    "# Write to JSON\n",
    "aggregated_df.write.mode(\"overwrite\").json(\"output/tourism_aggregated.json\")\n",
    "\n",
    "# Stop Spark Session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
