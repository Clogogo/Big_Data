{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4fd2eacd-c3ee-429f-9e53-03fdf253b9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "                    .appName('helloSpark')\n",
    "                    .getOrCreate()\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3ec7cc-5d7b-4319-b704-f2fc139af563",
   "metadata": {},
   "source": [
    "Further info on Spark sessions:  \n",
    "https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/spark_session.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "01f63dc4-1b2f-4959-9437-24fa9f592b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://82c14b214d5e:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>helloSpark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0xffff74f0ef90>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6ce07dab-127a-47b9-8b41-fe5ff62fb668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's generate some data for analysis\n",
    "\n",
    "import random\n",
    "\n",
    "names = [\"Alice\", \"Ben\", \"Charles\", \"Daisy\"]\n",
    "start_range = 900\n",
    "end_range = 5000\n",
    "python_data = [[random.choice(names),random.randint(start_range,end_range)] for i in range(500000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4a7fb01b-149a-416e-a09a-6ef50af25e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To read in a Python object (list, dict), we can use spark.createDataFrame\n",
    "# We define a schema to have nicer column names and avoid Spark having to infer the schema\n",
    "schema = \"name STRING, salary INT\"\n",
    "\n",
    "df = spark.createDataFrame(python_data,schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "44bc08ce-a374-499c-b98c-2e957dbebd0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|   name|salary|\n",
      "+-------+------+\n",
      "|    Ben|  3216|\n",
      "|  Alice|  1920|\n",
      "|  Alice|  3300|\n",
      "|    Ben|  4468|\n",
      "|  Alice|  1094|\n",
      "|Charles|  3456|\n",
      "|    Ben|  4487|\n",
      "|  Daisy|  1744|\n",
      "|Charles|  4603|\n",
      "|  Daisy|  1143|\n",
      "|Charles|  4781|\n",
      "|    Ben|  4084|\n",
      "|  Alice|  2825|\n",
      "|    Ben|  4284|\n",
      "|  Daisy|  3168|\n",
      "|Charles|  1723|\n",
      "|Charles|  1252|\n",
      "|  Alice|  4753|\n",
      "|  Daisy|  1271|\n",
      "|  Alice|  1840|\n",
      "+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# to display some rows, you can use .show() \n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d767b21f-c3fe-4516-9360-8dfb091bcd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = (df.groupBy(\"name\")\n",
    "          .avg(\"salary\")\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c569ead7-8bb5-4a5e-8085-f7e6f690b3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|   name|       avg(salary)|\n",
      "+-------+------------------+\n",
      "|Charles|2949.6538070415654|\n",
      "|    Ben| 2951.933745717701|\n",
      "|  Alice| 2945.608111883646|\n",
      "|  Daisy|  2948.88866524493|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_new.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9dc6c62f-d547-4f83-8fa6-5784aa35138b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------+\n",
      "|   name|       avg(salary)|average|\n",
      "+-------+------------------+-------+\n",
      "|Charles|2949.6538070415654| 2950.0|\n",
      "|    Ben| 2951.933745717701| 2952.0|\n",
      "|  Alice| 2945.608111883646| 2946.0|\n",
      "|  Daisy|  2948.88866524493| 2949.0|\n",
      "+-------+------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Many of the functions hide behind spark.sql.functions\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "(df_new.select(\n",
    "    \"name\"\n",
    "    ,\"avg(salary)\"\n",
    "    ,F.round(\"avg(salary)\").alias(\"average\")\n",
    "    ).show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3474a14-484b-433e-a794-c5533d4b5087",
   "metadata": {},
   "source": [
    "The following is for a comparison with the popular Python package `pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5ce745d0-a5d7-435a-9e40-1a3d01b8e59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "pd_df = pd.DataFrame(python_data,columns=[\"name\",\"salary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b7590a6d-41c5-453d-8cdc-74e38f313634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ben</td>\n",
       "      <td>3216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alice</td>\n",
       "      <td>1920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alice</td>\n",
       "      <td>3300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ben</td>\n",
       "      <td>4468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alice</td>\n",
       "      <td>1094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>Daisy</td>\n",
       "      <td>2495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>Daisy</td>\n",
       "      <td>1287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>Charles</td>\n",
       "      <td>3418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>Alice</td>\n",
       "      <td>4571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>Daisy</td>\n",
       "      <td>1731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           name  salary\n",
       "0           Ben    3216\n",
       "1         Alice    1920\n",
       "2         Alice    3300\n",
       "3           Ben    4468\n",
       "4         Alice    1094\n",
       "...         ...     ...\n",
       "499995    Daisy    2495\n",
       "499996    Daisy    1287\n",
       "499997  Charles    3418\n",
       "499998    Alice    4571\n",
       "499999    Daisy    1731\n",
       "\n",
       "[500000 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "19bde6d2-ebf6-4e88-ae66-7f8bf6e23883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alice</th>\n",
       "      <td>2945.608112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ben</th>\n",
       "      <td>2951.933746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Charles</th>\n",
       "      <td>2949.653807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daisy</th>\n",
       "      <td>2948.888665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              salary\n",
       "name                \n",
       "Alice    2945.608112\n",
       "Ben      2951.933746\n",
       "Charles  2949.653807\n",
       "Daisy    2948.888665"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_df.groupby(\"name\").mean(\"salary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0463103-efad-4c27-8698-bea7c575e7e9",
   "metadata": {},
   "source": [
    "Which of these seemed to be faster?  \n",
    "Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a323d65",
   "metadata": {},
   "source": [
    "Let's have a quick walkthrough of a few more PySpark methods.  \n",
    "For a longer (full) list of methods, see:  \n",
    "https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/dataframe.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "048b9e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+----------+------+\n",
      "|emp_id| name|department|salary|\n",
      "+------+-----+----------+------+\n",
      "|     1| John|        HR| 50000|\n",
      "|     2|Alice|        IT| 60000|\n",
      "|     3|  Bob|   Finance| 55000|\n",
      "+------+-----+----------+------+\n",
      "\n",
      "+----------+-------+\n",
      "|department|manager|\n",
      "+----------+-------+\n",
      "|        HR|   Anna|\n",
      "|        IT|  David|\n",
      "|   Finance|  Sarah|\n",
      "+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load CSV files into DataFrames\n",
    "employees_df = spark.read.option(\"header\", \"true\").csv(\"input/employees.csv\")\n",
    "departments_df = spark.read.option(\"header\", \"true\").csv(\"input/departments.csv\")\n",
    "\n",
    "employees_df.show()\n",
    "departments_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5cffedd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+----------+------+\n",
      "|emp_id| name|department|salary|\n",
      "+------+-----+----------+------+\n",
      "|     1| John|        HR| 50000|\n",
      "|     2|Alice|        IT| 60000|\n",
      "|     3|  Bob|   Finance| 55000|\n",
      "+------+-----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# convert salary from string to integer for proper filtering\n",
    "employees_df = employees_df.withColumn(\"salary\", F.col(\"salary\").cast(\"integer\"))\n",
    "\n",
    "employees_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ed39aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# use .filter() for ... filtering.\n",
    "filtered_df = employees_df.filter(F.col(\"salary\") > 55000)\n",
    "\n",
    "# use .select() for ... selecting (columns).\n",
    "selected_df = filtered_df.select(\"emp_id\", \"name\", \"department\", \"salary\")\n",
    "\n",
    "# use withColumnRenamed for renaming columns\n",
    "renamed_df = selected_df.withColumnRenamed(\"emp_id\", \"employee_id\")\n",
    "\n",
    "# use selectExpr() for projecting SQL expressions\n",
    "expr_df = renamed_df.selectExpr(\"employee_id\", \"name\", \"department\", \"salary\", \"salary / 12 as monthly_salary\")\n",
    "\n",
    "# use .join() for ... joining. Let's join with departments DataFrame on the 'department' column\n",
    "joined_df = expr_df.join(departments_df, on=\"department\", how=\"inner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36336f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# .write for writing. There are multiple more options you can see in the next classes.\n",
    "joined_df.write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"output/joined_employees\")\n",
    "\n",
    "# NB - Spark has lazy evaluation. It will only execute the code when it needs to.\n",
    "# This means that you can chain multiple transformations and actions together without any performance hit.\n",
    "# The code will only be executed when you call an action like .show() or .write()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "015ec86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------------+--------------------+-----------+----------+------------------+-----+\n",
      "|               date|  province_thai|        province_eng|region_thai|region_eng|          variable|value|\n",
      "+-------------------+---------------+--------------------+-----------+----------+------------------+-----+\n",
      "|2019-01-01 00:00:00|  กรุงเทพมหานคร|             Bangkok|    ภาคกลาง|   central|ratio_tourist_stay|93.37|\n",
      "|2019-01-01 00:00:00|         ลพบุรี|            Lopburi |    ภาคกลาง|   central|ratio_tourist_stay|61.32|\n",
      "|2019-01-01 00:00:00|พระนครศรีอยุธยา|Phra Nakhon Si Ay...|    ภาคกลาง|   central|ratio_tourist_stay|73.37|\n",
      "|2019-01-01 00:00:00|        สระบุรี|           Saraburi |    ภาคกลาง|   central|ratio_tourist_stay|67.33|\n",
      "|2019-01-01 00:00:00|         ชัยนาท|            Chainat |    ภาคกลาง|   central|ratio_tourist_stay|79.31|\n",
      "|2019-01-01 00:00:00|         นครปฐม|      Nakhon Pathom |    ภาคกลาง|   central|ratio_tourist_stay| 71.7|\n",
      "|2019-01-01 00:00:00|      สิงห์บุรี|          Sing Buri |    ภาคกลาง|   central|ratio_tourist_stay|64.65|\n",
      "|2019-01-01 00:00:00|        อ่างทอง|          Ang Thong |    ภาคกลาง|   central|ratio_tourist_stay|71.21|\n",
      "|2019-01-01 00:00:00|        นนทบุรี|         Nonthaburi |    ภาคกลาง|   central|ratio_tourist_stay|75.07|\n",
      "|2019-01-01 00:00:00|       ปทุมธานี|       Pathum Thani |    ภาคกลาง|   central|ratio_tourist_stay|60.77|\n",
      "|2019-01-01 00:00:00|    สมุทรปราการ|       Samut Prakan |    ภาคกลาง|   central|ratio_tourist_stay| 72.5|\n",
      "|2019-01-01 00:00:00|      สมุทรสาคร|       Samut Sakhon |    ภาคกลาง|   central|ratio_tourist_stay|61.64|\n",
      "|2019-01-01 00:00:00|     ฉะเชิงเทรา|       Chachoengsao |ภาคตะวันออก|      east|ratio_tourist_stay| 59.4|\n",
      "|2019-01-01 00:00:00|        ราชบุรี|         Ratchaburi |    ภาคกลาง|   central|ratio_tourist_stay|75.09|\n",
      "|2019-01-01 00:00:00|      กาญจนบุรี|       Kanchanaburi |    ภาคกลาง|   central|ratio_tourist_stay| 83.8|\n",
      "|2019-01-01 00:00:00|    สมุทรสงคราม|    Samut Songkhram |    ภาคกลาง|   central|ratio_tourist_stay| 75.6|\n",
      "|2019-01-01 00:00:00|     สุพรรณบุรี|        Suphan Buri |    ภาคกลาง|   central|ratio_tourist_stay|89.43|\n",
      "|2019-01-01 00:00:00|       เพชรบุรี|        Phetchaburi |    ภาคกลาง|   central|ratio_tourist_stay| 81.2|\n",
      "|2019-01-01 00:00:00|ประจวบคีรีขันธ์|Prachuap Khiri Khan |    ภาคกลาง|   central|ratio_tourist_stay|64.55|\n",
      "|2019-01-01 00:00:00|         ชลบุรี|           Chonburi |ภาคตะวันออก|      east|ratio_tourist_stay|84.33|\n",
      "+-------------------+---------------+--------------------+-----------+----------+------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, round\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"ThailandTourismAnalysis\").getOrCreate()\n",
    "\n",
    "# Read Parquet File\n",
    "df = spark.read.parquet(\"thailand_domestic_tourism_2019_2023_ver2.parquet\")\n",
    "\n",
    "# Let's view the data\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "38611168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: timestamp_ntz (nullable = true)\n",
      " |-- province_thai: string (nullable = true)\n",
      " |-- province_eng: string (nullable = true)\n",
      " |-- region_thai: string (nullable = true)\n",
      " |-- region_eng: string (nullable = true)\n",
      " |-- variable: string (nullable = true)\n",
      " |-- value: double (nullable = true)\n",
      "\n",
      "+-------------------+---------------+--------------------+-----------+----------+------------------+-----+\n",
      "|               date|  province_thai|        province_eng|region_thai|region_eng|          variable|value|\n",
      "+-------------------+---------------+--------------------+-----------+----------+------------------+-----+\n",
      "|2019-01-01 00:00:00|  กรุงเทพมหานคร|             Bangkok|    ภาคกลาง|   central|ratio_tourist_stay|93.37|\n",
      "|2019-01-01 00:00:00|         ลพบุรี|            Lopburi |    ภาคกลาง|   central|ratio_tourist_stay|61.32|\n",
      "|2019-01-01 00:00:00|พระนครศรีอยุธยา|Phra Nakhon Si Ay...|    ภาคกลาง|   central|ratio_tourist_stay|73.37|\n",
      "|2019-01-01 00:00:00|        สระบุรี|           Saraburi |    ภาคกลาง|   central|ratio_tourist_stay|67.33|\n",
      "|2019-01-01 00:00:00|         ชัยนาท|            Chainat |    ภาคกลาง|   central|ratio_tourist_stay|79.31|\n",
      "+-------------------+---------------+--------------------+-----------+----------+------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "Total records: 30800\n",
      "+-------+-------------+--------------+-----------+----------+--------------+-------------------+\n",
      "|summary|province_thai|  province_eng|region_thai|region_eng|      variable|              value|\n",
      "+-------+-------------+--------------+-----------+----------+--------------+-------------------+\n",
      "|  count|        30800|         30800|      30800|     30800|         30800|              30800|\n",
      "|   mean|         NULL|           NaN|       NULL|      NULL|          NULL|3.360336825309471E8|\n",
      "| stddev|         NULL|           NaN|       NULL|      NULL|          NULL|2.994696582046674E9|\n",
      "|    min|       กระบี่|Amnat Charoen |    ภาคกลาง|   central|no_tourist_all|            -4250.0|\n",
      "|    max|   แม่ฮ่องสอน|     Yasothon |     ภาคใต้|     south|  revenue_thai|       1.1028728E11|\n",
      "+-------+-------------+--------------+-----------+----------+--------------+-------------------+\n",
      "\n",
      "+-------------------+-----------------+---------------------------------+--------------------------------------+\n",
      "|               date|     province_eng|no_percentage_of_foreign_tourists|revenue_percentage_of_foreign_tourists|\n",
      "+-------------------+-----------------+---------------------------------+--------------------------------------+\n",
      "|2019-05-01 00:00:00|Ubon Ratchathani |                           0.0459|                                0.0796|\n",
      "|2022-09-01 00:00:00|        Saraburi |                           0.0039|                                0.0037|\n",
      "|2020-05-01 00:00:00|             Nan |                              0.0|                                   0.0|\n",
      "|2020-08-01 00:00:00|         Sisaket |                              0.0|                                   0.0|\n",
      "|2019-08-01 00:00:00|           Surin |                            0.017|                                0.0249|\n",
      "+-------------------+-----------------+---------------------------------+--------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Display Schema\n",
    "df.printSchema()\n",
    "\n",
    "# Show Sample Data\n",
    "df.show(5)\n",
    "\n",
    "# Exploratory Data Analysis\n",
    "print(f\"Total records: {df.count()}\")\n",
    "df.describe().show()\n",
    "\n",
    "# Assuming the correct columns are 'variable' and 'value'\n",
    "# Pivot the DataFrame to get the required columns\n",
    "pivot_df = df.groupBy(\"date\", \"province_eng\").pivot(\"variable\").sum(\"value\")\n",
    "\n",
    "# Calculate Required Aggregations\n",
    "aggregated_df = pivot_df.withColumn(\n",
    "    \"no_percentage_of_foreign_tourists\",\n",
    "    round(col(\"no_tourist_foreign\") / col(\"no_tourist_all\"), 4)\n",
    ").withColumn(\n",
    "    \"revenue_percentage_of_foreign_tourists\",\n",
    "    round(col(\"revenue_foreign\") / col(\"revenue_all\"), 4)\n",
    ").select(\n",
    "    \"date\", \"province_eng\", \"no_percentage_of_foreign_tourists\", \"revenue_percentage_of_foreign_tourists\"\n",
    ")\n",
    "\n",
    "# Show Aggregated Data\n",
    "aggregated_df.show(5)\n",
    "\n",
    "# Write to JSON\n",
    "aggregated_df.write.mode(\"overwrite\").json(\"output/tourism_aggregated.json\")\n",
    "\n",
    "# Stop Spark Session\n",
    "spark.stop()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
